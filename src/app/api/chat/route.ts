import { NextResponse } from 'next/server';
import { OpenAI } from 'openai';
import { Pinecone } from '@pinecone-database/pinecone';

// ğŸ”‘ åˆå§‹åŒ– OpenAI å’Œ Pinecone å®¢æˆ·ç«¯
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY!,
});

const pinecone = new Pinecone({
  apiKey: process.env.PINECONE_API_KEY!,
});

const INDEX_NAME = process.env.PINECONE_INDEX_NAME!;

export async function POST(req: Request) {
  const { message } = await req.json();

  if (!message) {
    return NextResponse.json({ reply: 'è¯·è¾“å…¥é—®é¢˜å†…å®¹ã€‚' });
  }

  try {
    // 1ï¸âƒ£ å°†ç”¨æˆ·é—®é¢˜è½¬ä¸º embedding
    const embeddingRes = await openai.embeddings.create({
      model: 'text-embedding-3-small',
      input: message,
    });
    const embedding = embeddingRes.data[0].embedding;

    // 2ï¸âƒ£ æŸ¥è¯¢ Pinecone ä¸­æœ€ç›¸å…³çš„ç®€å†ç‰‡æ®µ
    const index = pinecone.Index(INDEX_NAME);
    const queryRes = await index.query({
      vector: embedding,
      topK: 5,
      includeMetadata: true,
    });

    const matches = queryRes.matches || [];

    const context = matches.map((m) => m.metadata?.text).join('\n---\n');

    // 3ï¸âƒ£ ç”¨ ChatGPT å›ç­”é—®é¢˜ï¼ŒåŸºäºç®€å†ä¸Šä¸‹æ–‡
    const chatRes = await openai.chat.completions.create({
      model: 'gpt-4',
      messages: [
        {
          role: 'system',
          content: `ä½ æ˜¯ä¸€ä½æ­£åœ¨åº”è˜çš„å€™é€‰äººï¼Œè¯·æ ¹æ®ä»¥ä¸‹ç®€å†å†…å®¹å›ç­”é—®é¢˜ï¼š\n${context}`,
        },
        {
          role: 'user',
          content: message,
        },
      ],
    });
    const reply = chatRes.choices[0].message.content;

    return NextResponse.json({ reply });
  } catch (err: any) {
    console.error('[Chat API Error]', err);
    return NextResponse.json({ reply: 'æœåŠ¡å™¨å‘ç”Ÿé”™è¯¯ï¼Œè¯·ç¨åå†è¯•ã€‚' });
  }
}